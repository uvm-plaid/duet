module Duet.Interpreter where

import Duet.UVMHS

import Duet.Pretty ()
import Duet.Syntax
import Duet.RNF
import Duet.Quantity

-- libraries
-- import Text.CSV
-- import Text.Parsec.Error
-- import System.Environment
-- import Debug.Trace
-- import Numeric.Natural
-- import Control.Exception
-- import Data.Random.Normal

type Env = ğ• â‡° Val
type Vector v = ğ¿ v
type Matrix v = (â„• â‡° (â„• â‡° v))

-- | Returns maximum element
maxElem ::  Ord b => [(a, b)] -> a
maxElem = fst . maximumBy (comparing snd)

-- | Returns minimum element
minElem ::  Ord b => [(a, b)] -> a
minElem = fst . minimumBy (comparing snd)

-- | Defining Val algebraic data type
data Val =
  NatV Natural
  | RealV ğ”»
  | PairV Val Val
  | SFunV ğ• SExp Env
  | PFunV [ğ•] PExp Env
  | MatrixV (Matrix Val)
  deriving (Eq, Show)

-- | Converts and integer to a ğ”»
intDouble âˆ· â„• â†’ ğ”»
intDouble = fromIntegral

-- | Converts a natural number to a double
mkDouble âˆ· Natural â†’ ğ”»
mkDouble = fromIntegral

-- | Evaluates an expression from the sensitivity language
seval âˆ· Env â†’ SExp â†’ Val

-- literals
seval _ (â„•SE n)        = NatV n
seval _ (â„SE n)        = RealV n
seval _ (â„Ë¢SE n)       = RealV n
seval _ (â„•Ë¢SE n)       = NatV n
seval env (SRealNatE e) =
  case (seval env e) of
    (NatV n) -> RealV $ mkDouble n

-- variables
seval env (VarSE x) | x âˆˆ env  = env â‹•! x
                    | otherwise         = error $ "Unknown variable: " ++ (chars x) ++ " in environment with bound vars " ++ (chars $ sho $ keys env)

-- arithmetic
seval env (PlusSE eâ‚ eâ‚‚) =
  case (seval env eâ‚, seval env eâ‚‚) of
    (MatrixV vâ‚, MatrixV vâ‚‚) â†’ MatrixV (vâ‚ + vâ‚‚)
    (RealV vâ‚, RealV vâ‚‚) â†’ RealV (vâ‚ + vâ‚‚)
    (a, b) â†’ error $ "No pattern for " ++ (show (a, b))

seval env (MinusSE eâ‚ eâ‚‚) =
  case (seval env eâ‚, seval env eâ‚‚) of
    (MatrixV vâ‚, MatrixV vâ‚‚) â†’ MatrixV (vâ‚ - vâ‚‚)
    (RealV vâ‚, RealV vâ‚‚) â†’ RealV (vâ‚ - vâ‚‚)
    (a, b) â†’ error $ "No pattern for " ++ (show (a, b))

seval env (TimesSE eâ‚ eâ‚‚) =
  case (seval env eâ‚, seval env eâ‚‚) of
    (MatrixV vâ‚, MatrixV vâ‚‚) â†’ MatrixV (vâ‚ <> vâ‚‚)
    (RealV vâ‚, MatrixV vâ‚‚) â†’ MatrixV (scale vâ‚ vâ‚‚)
    (RealV vâ‚, RealV vâ‚‚) â†’ RealV (vâ‚ * vâ‚‚)
    (a, b) â†’ error $ "No pattern for " ++ (show (a, b))

seval env (DivSE eâ‚ eâ‚‚) =
  case (seval env eâ‚, seval env eâ‚‚) of
    (RealV vâ‚, RealV vâ‚‚) â†’ RealV (vâ‚ / vâ‚‚)
    (a, b) â†’ error $ "No pattern for " ++ (show (a, b))

-- matrix operations
seval env (MRowsSE e) =
  case (seval env e) of (MatrixV v) â†’
                         NatV $ nat $ rows v

seval env (MColsSE e) =
  case (seval env e) of (MatrixV v) â†’
                         NatV $ nat $ cols v

seval env (IdxSE e) =
  case seval env e of
    (NatV d) â†’
      let posMat âˆ· Matrix ğ”» = ident $ int d
          negMat âˆ· Matrix ğ”» = scale (-1.0) posMat
      in MatrixV (posMat === negMat)

seval env (SMTrE e) =
  case seval env e of (MatrixV m) â†’ MatrixV $ tr m

-- clip operation for only L2 norm
seval env (MClipSE norm e) =
  case (norm, seval env e) of
    (L2,   MatrixV v) â†’  MatrixV $ fromRows (map normalize $ toRows v)
    (LInf, MatrixV v) â†’  MatrixV $ fromRows (map normalize $ toRows v)
    (l, _) â†’ error $ "Invalid norm for clip: " ++ (show l)

-- gradient
seval env (SGradE LR _ eâ‚ eâ‚‚ e3) =
  case (seval env eâ‚, seval env eâ‚‚, seval env e3) of
    (MatrixV Î¸, MatrixV xs, MatrixV ys) â†’
      if (rows Î¸ == 1 && rows ys == 1)
      then
        let Î¸'  âˆ· Vector ğ”» = flatten Î¸
            ys' âˆ· Vector ğ”» = flatten ys
        in MatrixV $ asRow $ ngrad Î¸' xs ys'
      else
        error $ "Incorrect matrix dimensions for gradient: " ++ (show (rows Î¸, rows ys))
    (a, b, c) â†’ error $ "No pattern for " ++ (show (a, b, c))

-- create matrix
seval env (MCreateSE l eâ‚ eâ‚‚ i j eâ‚ƒ) =
  case (seval env eâ‚, seval env eâ‚‚) of
    (NatV vâ‚, NatV vâ‚‚) â†’
      MatrixV $ (><) (int vâ‚) (int vâ‚‚) $ replicate (int $ vâ‚ * vâ‚‚) 0.0

-- functions and application
seval env (PFunSE _ args body) =
  PFunV (map fst args) body env

seval env (SFunSE x _ body) =
  SFunV x body env

seval env (AppSE eâ‚ eâ‚‚) =
  case seval env eâ‚ of
    (SFunV x body env') â†’
      let env'' = (x â†¦ (seval env eâ‚‚)) â©Œ env'
      in seval env'' body

-- error
seval env e = error $ "Unknown expression: " ++ (show e)

-- | Evaluates an expression from the privacy language
peval âˆ· Env â†’ PExp â†’ IO Val

-- bind and application
peval env (BindPE x eâ‚ eâ‚‚) = do
  vâ‚ â† peval env eâ‚
  vâ‚‚ â† peval (x â†¦ vâ‚ â©Œ env) eâ‚‚
  return vâ‚‚

peval env (AppPE _ f vars) =
  case seval env f of
    (PFunV args body env') â†’
      let vs    âˆ· [Val] = map ((â‹•!) env) vars
          env'' âˆ· Env   = foldr (\(var, val) â†’ Map.insert var val) env' (zip args vs)
      in peval env'' body

-- sample on two matrices and compute on sample
peval env (SamplePE size xs ys x y e) =
  case (seval env size, env â‹•! xs, env â‹•! ys) of
    (NatV n, MatrixV v1, MatrixV v2) ->
      sampleHelper n v1 v2 x y e env

-- gaussian mechanism for real numbers
peval env (GaussPE r Îµ Î´ vs e) =
  case (seval env r, seval env Îµ, seval env  Î´, seval env e) of
    (RealV r', RealV Îµ', RealV Î´', RealV v) â†’ do
      r â† gaussianNoise 0 (r' * (sqrt $ 2 * (log $ 1.25/Î´')) / Îµ')
      return $ RealV $ v + r
    (a, b, c, d) â†’ error $ "No pattern for: " ++ (show (a,b,c,d))

-- gaussian mechanism for matrices
peval env (MGaussPE r Îµ Î´ vs e) =
  case (seval env r, seval env Îµ, seval env  Î´, seval env e) of
    (RealV r', RealV Îµ', RealV Î´', MatrixV mat) â†’ do
      let Ïƒ = (r' * (sqrt $ 2 * (log $ 1.25/Î´')) / Îµ')
      mat' â† mapM (\row â†’ mapM (\val â†’ gaussianNoise val Ïƒ) row) $ toLists mat
      return $ MatrixV $ fromLists mat'
    (a, b, c, d) â†’ error $ "No pattern for: " ++ (show (a,b,c,d))

-- evaluate finite iteration
peval env (LoopPE Î´' k init xs xâ‚ xâ‚‚ e) =
  case (seval env k, seval env init) of
    (NatV k', initV) â†’
      iter k' initV xâ‚ xâ‚‚ 0 e env

-- evaluate sensitivity expression and return in the context of the privacy language
peval env (ReturnPE e) =
  return $ seval env e

-- exponential mechanism
peval env (ExponentialPE s Îµ xs x body) =
  case (seval env s, seval env Îµ, seval env xs) of
    (RealV s', RealV Îµ', MatrixV xs') â†’
      let xs''     = map (\row' â†’ fromLists [row']) $ toLists xs'
          envs     = map (\m â†’ Map.insert x (MatrixV m) env) xs''
          getScore = \env1 â†’ case seval env1 body of
            (RealV   r) â†’ r
            (MatrixV m) | size m == (1, 1) â†’ head $ head $ toLists m
            a â†’ error $ "Invalid score: " ++ (chars $ sho a)
          scores   = map getScore envs
          Î´'       = 1e-5
          Ïƒ        = (s' * (sqrt $ 2 * (log $ 1.25/Î´')) / Îµ')
      in do
        scores' â† mapM (\score â†’ gaussianNoise score Ïƒ) scores
        --putStrLn $ "picked: " ++ (show $ maxElem (zip xs'' scores))
        return $ MatrixV $ minElem (zip xs'' scores')

-- error
peval env e = error $ "Unknown expression: " ++ (show e)


-- | Helper function for loop expressions
iter âˆ· Natural â†’ Val â†’ ğ• â†’ ğ• â†’ â„• â†’ PExp â†’ Env â†’ IO Val
iter 0 v _ _ _ _ _ = return v
iter k v t x kp body env = do
  newVal â† peval (x â†¦ v â©Œ (t â†¦ (NatV $ nat kp) â©Œ env) body)
  iter (k - 1) newVal t x (kp+1) body env

-- | Empty environment
emptyEnv âˆ· Env
emptyEnv = dÃ¸

-- | Read in a dataset and return xs (features) and ys (labels)
readDataSet âˆ· ğ•Š â†’ IO (Matrix ğ”», Vector ğ”»)
readDataSet fileName = do
    Right(mat) â† parseCSVtoMatrix fileName
    let dataCols âˆ· [Vector ğ”»] = toColumns mat
        xs âˆ· Matrix ğ”» = fromColumns $ tail dataCols
        ys âˆ· Vector ğ”» = head dataCols
    return $ (xs, ys)

-- | Place a dataset into the environment
insertDataSet âˆ· Env â†’ (ğ•, ğ•) â†’ (Matrix ğ”», Vector ğ”») â†’ Env
insertDataSet env (x, y) (xs, ys) =
  (x â†¦ (MatrixV xs) â©Œ (y â†¦ (MatrixV $ asRow ys) â©Œ env))

-- | Samples a normal distribution and returns a single value
gaussianNoise âˆ· ğ”» â†’ ğ”» â†’ IO ğ”»
gaussianNoise c v = normalIO'(c, v)

-- | Helper function for PSampleE
sampleHelper :: Natural -> Matrix ğ”» -> Matrix  ğ”» -> ğ• -> ğ• -> PExp -> Env -> IO Val
sampleHelper n xs ys x y e env = do
  batch <- minibatch (int n) xs (flatten ys)
  peval (insertDataSet env (x, y) ((fst batch), (snd batch))) e

-- GRADIENT --

type Model = Vector ğ”»

-- | Converts an Integral number to a double
dbl âˆ· (Integral a) â‡’ a â†’ ğ”»
dbl = fromIntegral

-- | Calculates LR loss
loss âˆ· Model â†’ Matrix ğ”» â†’ Vector ğ”» â†’ ğ”»
loss Î¸ x y =
  let Î¸'       âˆ· Matrix ğ”» = asColumn Î¸
      y'       âˆ· Matrix ğ”» = asColumn y
      exponent âˆ· Matrix ğ”» = -((x <> Î¸') * y')
  in (sumElements (log (1.0 + (exp exponent)))) / (dbl $ rows x)

-- | Averages LR gradient over the whole matrix of examples
ngrad âˆ· Model â†’ Matrix ğ”» â†’ Vector ğ”» â†’ Vector ğ”»
ngrad Î¸ x y =
  let Î¸'       âˆ· Matrix ğ”» = asColumn Î¸
      y'       âˆ· Matrix ğ”» = asColumn y
      exponent âˆ· Matrix ğ”» = (x <> Î¸') * y'
      scaled   âˆ· Matrix ğ”» = y' * (1.0/(1.0+exp(exponent)))
      gradSum  âˆ· Matrix ğ”» = (tr x) <> scaled
      avgGrad  âˆ· Vector ğ”» = flatten $ scale (1.0/(dbl $ rows x)) gradSum
  in (- avgGrad)

-- | Obtains a vector in the same direction with L2-norm=1
normalize :: Vector ğ”» -> Vector ğ”»
normalize v
  | r > 1     =  scale (1/r) v
  | otherwise =  v
  where
    r = norm_2 v

-- | Convert a string into a double
readStr âˆ· ğ•Š â†’ ğ”»
readStr s = case (reads s) of
  [(d, _)] â†’ d
  _ â†’ 0.0

-- | Reads a CSV into a matrix
parseCSVtoMatrix âˆ· FilePath â†’ IO (Either ParseError (Matrix ğ”»))
parseCSVtoMatrix file = do
  Right(csv) â† parseCSVFromFile file
  let csvList âˆ· [[ğ”»]] = map (map readStr) csv
      matrix âˆ· Matrix ğ”» = fromLists csvList
  return $ return matrix

-- | Performs gradient descent with a fixed learning rate
gradientDescent âˆ· â„• â†’ Model â†’ Matrix ğ”» â†’ Vector ğ”» â†’ ğ”» â†’ Model
gradientDescent 0 Î¸ x y Î· = Î¸
gradientDescent n Î¸ x y Î· = let Î¸' = Î¸ - (scale Î· $ ngrad Î¸ x y)
                            in trace ("training iter " ++ (show n) ++
                                      ", loss : " ++ (show $ loss Î¸ x y))
                               gradientDescent (n-1) Î¸' x y Î·

-- | Makes a single prediction
predict âˆ· Model â†’ (Vector ğ”», ğ”») â†’ ğ”»
predict Î¸ (x, y) = signum $ x <.> Î¸

isCorrect âˆ· (ğ”», ğ”») â†’ (â„•, â„•)
isCorrect (prediction, actual) | prediction == actual = (1, 0)
                               | otherwise = (0, 1)

-- | Converts a matrix to a model (flatten it)
toModel âˆ· Matrix ğ”» â†’ Model
toModel = flatten

-- | Calculates the accuracy of a model
accuracy âˆ· Matrix ğ”» â†’ Vector ğ”» â†’ Model â†’ (â„•, â„•)
accuracy x y Î¸ = let pairs âˆ· [(Vector ğ”», ğ”»)] = zip (map normalize $ toRows x) (toList y)
                     labels âˆ· [ğ”»] = map (predict Î¸) pairs
                     correct âˆ· [(â„•, â„•)] = map isCorrect $ zip labels (toList y)
                 in foldl' (\a b â†’ (fst a + fst b, snd a + snd b)) (0, 0) correct

-- | Ensures that labels are either 1 or -1
fixLabel âˆ· ğ”» â†’ ğ”»
fixLabel x | x == -1.0 = -1.0
           | x == 1.0 = 1.0
           | otherwise = trace ("Unexpected label: " ++ (show x)) x

-- END GRADIENT --

-- MINIBATCHGRADIENT --

-- | Generates random indicies for sampling
randIndices :: â„• -> â„• -> â„• -> GenIO -> IO [â„•]
randIndices n a b gen
  | n == 0    = return []
  | otherwise = do
      x <- uniformR (a, b) gen
      xs' <- randIndices (n - 1) a b gen
      return (x : xs')

-- | Outputs a single minibatch of data
minibatch :: â„• -> Matrix ğ”» -> Vector ğ”» -> IO (Matrix ğ”», Vector ğ”»)
minibatch batchSize xs ys = do
  gen <- createSystemRandom
  idxs <- randIndices batchSize 0 (rows xs - 1) gen
  let bxs = xs ? idxs
      bys = head $ toColumns $ (asColumn ys) ? idxs
  return (bxs, bys)

-- | Generates a list of minibatches
nminibatch :: â„• -> â„• -> Matrix ğ”» -> Vector ğ”» -> IO [(Matrix ğ”», Vector ğ”»)]
nminibatch n batchSize x y
  | n == 0    = return []
  | otherwise = do
      x' <- minibatch batchSize x y
      xs <- nminibatch (n - 1) batchSize x y
      return (x' : xs)

-- | Returns an infinite list of random values sampled from a normal distribution
noise :: â„• -> â„• -> ğ”» -> ğ”» -> ğ”» -> IO [ğ”»]
noise n iters lreg eps delta =
  let stdDev = 4 * lreg * (sqrt (fromIntegral(iters) * (log (1 / delta)))) / (fromIntegral(n) * eps)
  in normalsIO' (0, stdDev)

-- | Generates a list of random numbers sampled from a [0, 1) uniform distribution
randUniform :: â„• -> IO[ğ”»]
randUniform n
  | n == 0    = return []
  | otherwise = do
      x <- randomIO
      xs <- randUniform (n - 1)
      return (x : xs)

-- | Initializes model and regularization parameter
initModel :: â„• -> ğ”» -> ğ”» -> ğ‘‚ ğ”» ->  IO (Vector ğ”», ğ”»)
initModel m l lambda l2 = do
  rand <- randUniform m
  case (lambda, l2) of
    (0, None) -> return (fromList $ replicate m 0.0, l)
    (lambda, Some l2) | lambda > 0 ->
      return ((scale (2 * l2) (vector (map (subtract 0.5) rand))), l + lambda*l2)
    otherwise -> return (fromList $ replicate m 0.0, 0)

-- | Runs gradient descent on an initial model and a set of minibatches
mbgradientDescent :: â„• -> â„•  -> Model -> [(Matrix ğ”», Vector ğ”»)] -> ğ”» ->  [ğ”»] -> Model
mbgradientDescent 0 m theta batches rate noise = theta
mbgradientDescent n m theta batches rate noise =
  let x = (fst (head batches))
      y = (snd (head batches))
      grad = ((ngrad theta x y) + (vector (take m noise)))
      theta' = theta - (scale rate grad)
  in trace ("training iter " ++ (show n) ++
               ", loss : " ++ (show $ loss theta x y) ++
               ", noise :" ++ (show $ take 5 noise))
     mbgradientDescent (n - 1) m theta' (tail batches) rate noise

{- | Runs differentially private, minibatch gradient descent on input matrices
     `x` and `y` and a set of input parameters.
-}
privateMBSGD :: Matrix ğ”»
            -> Vector ğ”»
            -> ğ”»
            -> ğ”»
            -> â„•
            -> ğ”»
            -> ğ”»
            -> â„•
            -> ğ”»
            -> ğ‘‚ ğ”»
            -> IO Model
privateMBSGD x y eps delta iters learningRate l batchSize lambda l2 = do
  init <- initModel (cols x) l lambda l2
  normalNoise <- noise (rows x) iters (snd init) eps delta
  minibatches <- nminibatch iters batchSize x y
  return (mbgradientDescent iters (cols x) (fst init) minibatches learningRate normalNoise)

-- | Runs noiseless minibatch gradient descent.
mbSGD :: Matrix ğ”»
            -> Vector ğ”»
            -> ğ”»
            -> ğ”»
            -> â„•
            -> ğ”»
            -> ğ”»
            -> â„•
            -> ğ”»
            -> ğ‘‚ ğ”»
            -> IO Model
mbSGD x y eps delta iters learningRate l batchSize lambda l2 = do
  init <- initModel (cols x) l lambda l2
  minibatches <- nminibatch iters batchSize x y
  return (mbgradientDescent iters (cols x) (fst init) minibatches learningRate (iterate (+0.0) 0))

-- END MINIBATCHGRADIENT --
